{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b776b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loadData import DIV2K\n",
    "from model import Generator, Discriminator\n",
    "from trainer import SrganTrainer, SrganGeneratorTrainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d25dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the high-resolution training dataset\n",
    "if not os.path.exists('.div2k/images/DIV2K_train_HR'):\n",
    "    DIV2K.download_archive('DIV2K_train_HR.zip', '.div2k/images')\n",
    "if not os.path.exists('.div2k/images/DIV2K_train_LR_x8'):\n",
    "    DIV2K.download_archive('DIV2K_train_LR_x8.zip', '.div2k/images')\n",
    "if not os.path.exists('.div2k/images/DIV2K_valid_HR'):\n",
    "    DIV2K.download_archive('DIV2K_valid_HR.zip', '.div2k/images')\n",
    "if not os.path.exists('.div2k/images/DIV2K_valid_HR'):\n",
    "    DIV2K.download_archive('DIV2K_valid_LR_x8.zip', '.div2k/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec60e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching dataset to .div2k/caches/DIV2K_train_HR.cache ...\n",
      "Dataset cached to .div2k/caches/DIV2K_train_HR.cache.\n",
      "Caching dataset to .div2k/caches/DIV2K_train_LR_x8_X8.cache ...\n",
      "Dataset cached to .div2k/caches/DIV2K_train_LR_x8_X8.cache.\n",
      "Caching dataset to .div2k/caches/DIV2K_valid_HR.cache ...\n",
      "Dataset cached to .div2k/caches/DIV2K_valid_HR.cache.\n",
      "Caching dataset to .div2k/caches/DIV2K_valid_LR_x8_X8.cache ...\n",
      "Dataset cached to .div2k/caches/DIV2K_valid_LR_x8_X8.cache.\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the DIV2K class implemented or imported\n",
    "div2k_train = DIV2K(scale=8, subset='train', downgrade='bicubic')\n",
    "div2k_valid = DIV2K(scale=8, subset='valid', downgrade='bicubic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dcf596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR Directory Exists: True\n",
      "LR Directory Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Check if high-resolution images are downloaded\n",
    "hr_dir = div2k_train._hr_images_dir()\n",
    "lr_dir = div2k_train._lr_images_dir()\n",
    "\n",
    "print(f\"HR Directory Exists: {os.path.exists(hr_dir)}\")\n",
    "print(f\"LR Directory Exists: {os.path.exists(lr_dir)}\")\n",
    "\n",
    "# Manually trigger the download if needed\n",
    "if not os.path.exists(hr_dir):\n",
    "    DIV2K.download_archive(div2k_train._hr_images_archive(), div2k_train.images_dir, extract=True)\n",
    "\n",
    "if not os.path.exists(lr_dir):\n",
    "    DIV2K.download_archive(div2k_train._lr_images_archive(), div2k_train.images_dir, extract=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98accc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "div2k_train = DIV2K(scale=4, subset='train', downgrade='bicubic')\n",
    "div2k_valid = DIV2K(scale=4, subset='valid', downgrade='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3010cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader for the training dataset with random transformations\n",
    "train_loader = DataLoader(dataset=div2k_train,\n",
    "                          batch_size=16,\n",
    "                          shuffle=True,  # Shuffles the data for each epoch\n",
    "                          num_workers=4,  # Number of subprocesses to use for data loading\n",
    "                          pin_memory=True)  # Copies Tensors into CUDA pinned memory before returning them\n",
    "\n",
    "# DataLoader for the validation dataset\n",
    "valid_loader = DataLoader(dataset=div2k_valid,\n",
    "                          batch_size=16,\n",
    "                          shuffle=False,  # No need to shuffle validation data\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f024b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator model\n",
    "generator = Generator()\n",
    "\n",
    "# Initialize the trainer for the generator\n",
    "pre_trainer = SrganGeneratorTrainer(model=generator, checkpoint_dir='./ckpt/pre_generator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cc368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the generator\n",
    "pre_trainer.train(train_loader, \n",
    "                  valid_loader, \n",
    "                  steps=1000000, \n",
    "                  evaluate_every=1000, \n",
    "                  save_best_only=False)\n",
    "# Save the model weights\n",
    "torch.save(generator.state_dict(), 'pre_generator.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820eb21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
