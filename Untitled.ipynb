{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b776b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loadData import DIV2K\n",
    "from model import Generator, Discriminator\n",
    "from trainer import SrganTrainer, SrganGeneratorTrainer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d25dfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading DIV2K_train_HR.zip: 3.29GB [25:06, 2.34MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download and extract the high-resolution training dataset\n",
    "DIV2K.download_archive('DIV2K_train_HR.zip', '.div2k/images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec60e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching dataset to .div2k/caches/DIV2K_train_HR.cache ...\n",
      "Dataset cached to .div2k/caches/DIV2K_train_HR.cache.\n",
      "Caching dataset to .div2k/caches/DIV2K_train_LR_bicubic_X4.cache ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.div2k/images/DIV2K_train_LR_bicubic/X4/0001x4.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have the DIV2K class implemented or imported\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m div2k_train \u001b[38;5;241m=\u001b[39m \u001b[43mDIV2K\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowngrade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbicubic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m div2k_valid \u001b[38;5;241m=\u001b[39m DIV2K(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, downgrade\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicubic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/faks/racunarska inteligencija/video-super-resolution/loadData.py:74\u001b[0m, in \u001b[0;36mDIV2K.__init__\u001b[0;34m(self, scale, subset, downgrade, images_dir, caches_dir)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Cache the datasets\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhr_images, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hr_cache_file())\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lr_cache_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/faks/racunarska inteligencija/video-super-resolution/loadData.py:128\u001b[0m, in \u001b[0;36mDIV2K._cache_dataset\u001b[0;34m(self, image_files, cache_file)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCaching dataset to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Simulate caching by accessing all images once\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset cached to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2950\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 2953\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2954\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.div2k/images/DIV2K_train_LR_bicubic/X4/0001x4.png'"
     ]
    }
   ],
   "source": [
    "# Assuming you have the DIV2K class implemented or imported\n",
    "div2k_train = DIV2K(scale=4, subset='train', downgrade='bicubic')\n",
    "div2k_valid = DIV2K(scale=4, subset='valid', downgrade='bicubic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0dcf596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if high-resolution images are downloaded\n",
    "hr_dir = div2k_train._hr_images_dir()\n",
    "lr_dir = div2k_train._lr_images_dir()\n",
    "\n",
    "print(f\"HR Directory Exists: {os.path.exists(hr_dir)}\")\n",
    "print(f\"LR Directory Exists: {os.path.exists(lr_dir)}\")\n",
    "\n",
    "# Manually trigger the download if needed\n",
    "if not os.path.exists(hr_dir):\n",
    "    DIV2K.download_archive(div2k_train._hr_images_archive(), div2k_train.images_dir, extract=True)\n",
    "\n",
    "if not os.path.exists(lr_dir):\n",
    "    DIV2K.download_archive(div2k_train._lr_images_archive(), div2k_train.images_dir, extract=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98accc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "div2k_train = DIV2K(scale=4, subset='train', downgrade='bicubic')\n",
    "div2k_valid = DIV2K(scale=4, subset='valid', downgrade='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3010cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader for the training dataset with random transformations\n",
    "train_loader = DataLoader(dataset=div2k_train,\n",
    "                          batch_size=16,\n",
    "                          shuffle=True,  # Shuffles the data for each epoch\n",
    "                          num_workers=4,  # Number of subprocesses to use for data loading\n",
    "                          pin_memory=True)  # Copies Tensors into CUDA pinned memory before returning them\n",
    "\n",
    "# DataLoader for the validation dataset\n",
    "valid_loader = DataLoader(dataset=div2k_valid,\n",
    "                          batch_size=16,\n",
    "                          shuffle=False,  # No need to shuffle validation data\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3f024b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generator model\n",
    "generator = Generator()\n",
    "\n",
    "# Initialize the trainer for the generator\n",
    "pre_trainer = SrganGeneratorTrainer(model=generator, checkpoint_dir='./ckpt/pre_generator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988cc368",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nemanja/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/nemanja/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/nemanja/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/nemanja/Desktop/faks/racunarska inteligencija/video-super-resolution/loadData.py\", line 71, in __getitem__\n    # Cache the datasets\n  File \"/usr/lib/python3/dist-packages/PIL/Image.py\", line 2953, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'DIV2K/DIV2K_train_HR/0638.png'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the generator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpre_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mevaluate_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                  \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Save the model weights\u001b[39;00m\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(generator\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_generator.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/faks/racunarska inteligencija/video-super-resolution/trainer.py:43\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, valid_loader, steps, evaluate_every, save_best_only)\u001b[0m\n\u001b[1;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m((steps \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_batches) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lr, hr \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     44\u001b[0m         step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     46\u001b[0m         lr, hr \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice), hr\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nemanja/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/nemanja/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/nemanja/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/nemanja/Desktop/faks/racunarska inteligencija/video-super-resolution/loadData.py\", line 71, in __getitem__\n    # Cache the datasets\n  File \"/usr/lib/python3/dist-packages/PIL/Image.py\", line 2953, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'DIV2K/DIV2K_train_HR/0638.png'\n"
     ]
    }
   ],
   "source": [
    "# Train the generator\n",
    "pre_trainer.train(train_loader, \n",
    "                  valid_loader, \n",
    "                  steps=1000000, \n",
    "                  evaluate_every=1000, \n",
    "                  save_best_only=False)\n",
    "# Save the model weights\n",
    "torch.save(generator.state_dict(), 'pre_generator.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820eb21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
