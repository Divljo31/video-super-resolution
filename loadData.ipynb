{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacfd7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3cd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIV2K(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 scale=2,\n",
    "                 subset='train',\n",
    "                 downgrade='bicubic',\n",
    "                 images_dir='.div2k/images',\n",
    "                 caches_dir='.div2k/caches'):\n",
    "\n",
    "        self._ntire_2018 = True\n",
    "\n",
    "        _scales = [2, 3, 4, 8]\n",
    "\n",
    "        if scale in _scales:\n",
    "            self.scale = scale\n",
    "        else:\n",
    "            raise ValueError(f'scale must be in {_scales}')\n",
    "\n",
    "        if subset == 'train':\n",
    "            self.image_ids = range(1, 801)\n",
    "        elif subset == 'valid':\n",
    "            self.image_ids = range(801, 901)\n",
    "        else:\n",
    "            raise ValueError(\"subset must be 'train' or 'valid'\")\n",
    "\n",
    "        _downgrades_a = ['bicubic', 'unknown']\n",
    "        _downgrades_b = ['mild', 'difficult']\n",
    "\n",
    "        if scale == 8 and downgrade != 'bicubic':\n",
    "            raise ValueError(f'scale 8 only allowed for bicubic downgrade')\n",
    "\n",
    "        if downgrade in _downgrades_b and scale != 4:\n",
    "            raise ValueError(f'{downgrade} downgrade requires scale 4')\n",
    "\n",
    "        if downgrade == 'bicubic' and scale == 8:\n",
    "            self.downgrade = 'x8'\n",
    "        elif downgrade in _downgrades_b:\n",
    "            self.downgrade = downgrade\n",
    "        else:\n",
    "            self.downgrade = downgrade\n",
    "            self._ntire_2018 = False\n",
    "\n",
    "        self.subset = subset\n",
    "        self.images_dir = images_dir\n",
    "        self.caches_dir = caches_dir\n",
    "\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        os.makedirs(caches_dir, exist_ok=True)\n",
    "\n",
    "        self.hr_images = self._hr_image_files()\n",
    "        self.lr_images = self._lr_image_files()\n",
    "\n",
    "        # Cache the datasets\n",
    "        self._cache_dataset(self.hr_images, self._hr_cache_file())\n",
    "        self._cache_dataset(self.lr_images, self._lr_cache_file())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr_image = Image.open(self.hr_images[idx])\n",
    "        lr_image = Image.open(self.lr_images[idx])\n",
    "\n",
    "        hr_image, lr_image = self.random_transform(lr_image, hr_image)\n",
    "\n",
    "        return transforms.ToTensor()(lr_image), transforms.ToTensor()(hr_image)\n",
    "\n",
    "    def random_transform(self, lr_image, hr_image):\n",
    "        lr_image, hr_image = random_crop(lr_image, hr_image, scale=self.scale)\n",
    "        if torch.rand(1).item() > 0.5:\n",
    "            lr_image, hr_image = random_flip(lr_image, hr_image)\n",
    "        lr_image, hr_image = random_rotate(lr_image, hr_image)\n",
    "        return lr_image, hr_image\n",
    "\n",
    "    def _hr_image_files(self):\n",
    "        images_dir = self._hr_images_dir()\n",
    "        return [os.path.join(images_dir, f'{image_id:04}.png') for image_id in self.image_ids]\n",
    "\n",
    "    def _lr_image_files(self):\n",
    "        images_dir = self._lr_images_dir()\n",
    "        return [os.path.join(images_dir, self._lr_image_file(image_id)) for image_id in self.image_ids]\n",
    "\n",
    "    def _lr_image_file(self, image_id):\n",
    "        if not self._ntire_2018 or self.scale == 8:\n",
    "            return f'{image_id:04}x{self.scale}.png'\n",
    "        else:\n",
    "            return f'{image_id:04}x{self.scale}{self.downgrade[0]}.png'\n",
    "\n",
    "    def _hr_images_dir(self):\n",
    "        return os.path.join(self.images_dir, f'DIV2K_{self.subset}_HR')\n",
    "\n",
    "    def _lr_images_dir(self):\n",
    "        if self._ntire_2018:\n",
    "            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}')\n",
    "        else:\n",
    "            return os.path.join(self.images_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}', f'X{self.scale}')\n",
    "\n",
    "    def _hr_cache_file(self):\n",
    "        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_HR.cache')\n",
    "\n",
    "    def _lr_cache_file(self):\n",
    "        return os.path.join(self.caches_dir, f'DIV2K_{self.subset}_LR_{self.downgrade}_X{self.scale}.cache')\n",
    "\n",
    "    def _cache_dataset(self, image_files, cache_file):\n",
    "        if not os.path.exists(cache_file):\n",
    "            print(f'Caching dataset to {cache_file} ...')\n",
    "            for image_file in image_files:\n",
    "                # Simulate caching by accessing all images once\n",
    "                Image.open(image_file).load()\n",
    "            print(f'Dataset cached to {cache_file}.')\n",
    "\n",
    "    @staticmethod\n",
    "    def download_archive(file, target_dir, extract=True):\n",
    "        source_url = f'http://data.vision.ee.ethz.ch/cvl/DIV2K/{file}'\n",
    "        target_path = os.path.join(target_dir, file)\n",
    "\n",
    "        # Send a request to get the file size for progress tracking\n",
    "        response = requests.head(source_url)\n",
    "        file_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "        # Download the file with a progress bar\n",
    "        response = requests.get(source_url, stream=True)\n",
    "        with open(target_path, 'wb') as f, tqdm(\n",
    "            desc=f'Downloading {file}',\n",
    "            total=file_size,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as bar:\n",
    "            for data in response.iter_content(chunk_size=1024):\n",
    "                f.write(data)\n",
    "                bar.update(len(data))\n",
    "\n",
    "        # Extract the file\n",
    "        if extract:\n",
    "            with ZipFile(target_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(target_dir)\n",
    "\n",
    "        # Remove the zip file\n",
    "        os.remove(target_path)\n",
    "        \n",
    "# -----------------------------------------------------------\n",
    "#  Transformations\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "def random_crop(lr_img, hr_img, hr_crop_size=96, scale=2):\n",
    "    lr_crop_size = hr_crop_size // scale\n",
    "\n",
    "    lr_w = torch.randint(0, lr_img.width - lr_crop_size + 1, (1,)).item()\n",
    "    lr_h = torch.randint(0, lr_img.height - lr_crop_size + 1, (1,)).item()\n",
    "\n",
    "    hr_w = lr_w * scale\n",
    "    hr_h = lr_h * scale\n",
    "\n",
    "    lr_img_cropped = lr_img.crop((lr_w, lr_h, lr_w + lr_crop_size, lr_h + lr_crop_size))\n",
    "    hr_img_cropped = hr_img.crop((hr_w, hr_h, hr_w + hr_crop_size, hr_h + hr_crop_size))\n",
    "\n",
    "    return lr_img_cropped, hr_img_cropped\n",
    "\n",
    "def random_flip(lr_img, hr_img):\n",
    "    if torch.rand(1).item() > 0.5:\n",
    "        return lr_img.transpose(Image.FLIP_LEFT_RIGHT), hr_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    else:\n",
    "        return lr_img, hr_img\n",
    "\n",
    "def random_rotate(lr_img, hr_img):\n",
    "    angle = torch.randint(0, 4, (1,)).item() * 90\n",
    "    return lr_img.rotate(angle), hr_img.rotate(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbaa5dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f700f8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ec56ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ce6df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
