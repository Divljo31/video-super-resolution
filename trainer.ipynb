{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7dcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c27e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, loss, learning_rate, checkpoint_dir='./ckpt'):\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.checkpoint_file = os.path.join(checkpoint_dir, 'model_checkpoint.pth')\n",
    "        self.best_psnr = -1\n",
    "\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        self.restore()\n",
    "\n",
    "    def train(self, train_loader, valid_loader, steps, evaluate_every=1000, save_best_only=False):\n",
    "        loss_mean = 0.0\n",
    "        num_batches = len(train_loader)\n",
    "        step = 0\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        for epoch in range((steps // num_batches) + 1):\n",
    "            for lr, hr in train_loader:\n",
    "                step += 1\n",
    "\n",
    "                lr, hr = lr.to(self.model.device), hr.to(self.model.device)\n",
    "                loss = self.train_step(lr, hr)\n",
    "                loss_mean += loss.item()\n",
    "\n",
    "                if step % evaluate_every == 0:\n",
    "                    avg_loss = loss_mean / evaluate_every\n",
    "                    loss_mean = 0.0\n",
    "\n",
    "                    psnr_value = self.evaluate(valid_loader)\n",
    "\n",
    "                    duration = time.perf_counter() - start_time\n",
    "                    print(f'{step}/{steps}: loss = {avg_loss:.3f}, PSNR = {psnr_value:.3f} ({duration:.2f}s)')\n",
    "\n",
    "                    if save_best_only and psnr_value <= self.best_psnr:\n",
    "                        start_time = time.perf_counter()\n",
    "                        continue\n",
    "\n",
    "                    self.best_psnr = psnr_value\n",
    "                    self.save_checkpoint()\n",
    "\n",
    "                    start_time = time.perf_counter()\n",
    "\n",
    "                if step >= steps:\n",
    "                    break\n",
    "\n",
    "    def train_step(self, lr, hr):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        sr = self.model(lr)\n",
    "        loss = self.loss(sr, hr)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        self.model.eval()\n",
    "        total_psnr = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for lr, hr in data_loader:\n",
    "                lr, hr = lr.to(self.model.device), hr.to(self.model.device)\n",
    "                sr = self.model(lr)\n",
    "                total_psnr += self.psnr(sr, hr)\n",
    "\n",
    "        avg_psnr = total_psnr / len(data_loader)\n",
    "        self.model.train()\n",
    "        return avg_psnr\n",
    "\n",
    "    def psnr(self, sr, hr):\n",
    "        mse = nn.functional.mse_loss(sr, hr)\n",
    "        return 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'best_psnr': self.best_psnr,\n",
    "        }\n",
    "        torch.save(checkpoint, self.checkpoint_file)\n",
    "        print(f'Checkpoint saved at {self.checkpoint_file}')\n",
    "\n",
    "    def restore(self):\n",
    "        if os.path.exists(self.checkpoint_file):\n",
    "            checkpoint = torch.load(self.checkpoint_file)\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            self.best_psnr = checkpoint['best_psnr']\n",
    "            print(f'Model restored from checkpoint with PSNR: {self.best_psnr:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c49c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrganTrainer:\n",
    "    def __init__(self, generator, discriminator, content_loss='VGG54', learning_rate=1e-4):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "        # Load VGG19 model for content loss\n",
    "        if content_loss == 'VGG22':\n",
    "            self.vgg = self._vgg_22()\n",
    "        elif content_loss == 'VGG54':\n",
    "            self.vgg = self._vgg_54()\n",
    "        else:\n",
    "            raise ValueError(\"content_loss must be either 'VGG22' or 'VGG54'\")\n",
    "\n",
    "        self.generator_optimizer = optim.Adam(self.generator.parameters(), lr=learning_rate)\n",
    "        self.discriminator_optimizer = optim.Adam(self.discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "        self.binary_cross_entropy = nn.BCELoss()\n",
    "        self.mean_squared_error = nn.MSELoss()\n",
    "\n",
    "    def train(self, train_loader, steps=200000):\n",
    "        perceptual_loss_mean = 0.0\n",
    "        discriminator_loss_mean = 0.0\n",
    "        num_batches = len(train_loader)\n",
    "        step = 0\n",
    "\n",
    "        for epoch in range((steps // num_batches) + 1):\n",
    "            for lr, hr in train_loader:\n",
    "                step += 1\n",
    "\n",
    "                lr, hr = lr.to(self.generator.device), hr.to(self.generator.device)\n",
    "\n",
    "                perceptual_loss, discriminator_loss = self.train_step(lr, hr)\n",
    "                perceptual_loss_mean += perceptual_loss.item()\n",
    "                discriminator_loss_mean += discriminator_loss.item()\n",
    "\n",
    "                if step % 50 == 0:\n",
    "                    avg_perceptual_loss = perceptual_loss_mean / 50\n",
    "                    avg_discriminator_loss = discriminator_loss_mean / 50\n",
    "                    print(f'{step}/{steps}, perceptual loss = {avg_perceptual_loss:.4f}, discriminator loss = {avg_discriminator_loss:.4f}')\n",
    "                    perceptual_loss_mean = 0.0\n",
    "                    discriminator_loss_mean = 0.0\n",
    "\n",
    "                if step >= steps:\n",
    "                    break\n",
    "\n",
    "    def train_step(self, lr, hr):\n",
    "        self.generator_optimizer.zero_grad()\n",
    "        self.discriminator_optimizer.zero_grad()\n",
    "\n",
    "        sr = self.generator(lr)\n",
    "\n",
    "        hr_output = self.discriminator(hr)\n",
    "        sr_output = self.discriminator(sr)\n",
    "\n",
    "        con_loss = self._content_loss(hr, sr)\n",
    "        gen_loss = self._generator_loss(sr_output)\n",
    "        perc_loss = con_loss + 0.001 * gen_loss\n",
    "        disc_loss = self._discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "        perc_loss.backward(retain_graph=True)\n",
    "        disc_loss.backward()\n",
    "\n",
    "        self.generator_optimizer.step()\n",
    "        self.discriminator_optimizer.step()\n",
    "\n",
    "        return perc_loss, disc_loss\n",
    "\n",
    "    def _content_loss(self, hr, sr):\n",
    "        sr = self.preprocess_input(sr)\n",
    "        hr = self.preprocess_input(hr)\n",
    "        sr_features = self.vgg(sr) / 12.75\n",
    "        hr_features = self.vgg(hr) / 12.75\n",
    "        return self.mean_squared_error(sr_features, hr_features)\n",
    "\n",
    "    def _generator_loss(self, sr_out):\n",
    "        return self.binary_cross_entropy(torch.ones_like(sr_out), sr_out)\n",
    "\n",
    "    def _discriminator_loss(self, hr_out, sr_out):\n",
    "        hr_loss = self.binary_cross_entropy(torch.ones_like(hr_out), hr_out)\n",
    "        sr_loss = self.binary_cross_entropy(torch.zeros_like(sr_out), sr_out)\n",
    "        return hr_loss + sr_loss\n",
    "\n",
    "    def preprocess_input(self, x):\n",
    "        x = x * 0.5 + 0.5  # De-normalize to [0, 1]\n",
    "        return transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(x)\n",
    "\n",
    "    def _vgg_22(self):\n",
    "        vgg = vgg19(pretrained=True).features[:5]\n",
    "        return nn.Sequential(*vgg).eval()\n",
    "\n",
    "    def _vgg_54(self):\n",
    "        vgg = vgg19(pretrained=True).features[:20]\n",
    "        return nn.Sequential(*vgg).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8e108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
